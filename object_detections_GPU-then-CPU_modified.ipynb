{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(\"/home/shuo/Shuo/tensorflow_models/research\")\n",
    "sys.path.append(\"/home/shuo/Shuo/tensorflow_models/research/object_detection\")\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ZOO = [\n",
    "            'faster_rcnn_inception_resnet_v2_atrous_coco',                   # 0  .37\n",
    "            'faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco',      # 1  \n",
    "            'faster_rcnn_inception_v2_coco',                                 # 2  .28\n",
    "            'faster_rcnn_nas_coco',                                          # 3  .43\n",
    "            'faster_rcnn_nas_lowproposals_coco',                             # 4  \n",
    "            'faster_rcnn_resnet50_coco',                                     # 5  .30\n",
    "            'faster_rcnn_resnet50_lowproposals_coco',                        # 6  \n",
    "            'faster_rcnn_resnet101_coco',                                    # 7  .32\n",
    "            'faster_rcnn_resnet101_kitti',                                   # 8  .87\n",
    "            'faster_rcnn_resnet101_lowproposals_coco',                       # 9  \n",
    "            'rfcn_resnet101_coco',                                           # 10 .30\n",
    "            'ssd_inception_v2_coco',                                         # 11 .24\n",
    "            'ssd_mobilenet_v1_coco'                                          # 12 .21\n",
    "            ]  \n",
    "\n",
    "USE_MODEL_ID = 12\n",
    "\n",
    "MODEL_NAME = MODEL_ZOO[USE_MODEL_ID]\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = '/home/shuo/Shuo/tensorflow_models/research/object_detection/off_the_shelf_models/' + MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# ssd_mobilenet\n",
    "cut_node_1 = \"Postprocessor/convert_scores\"\n",
    "cut_node_2 = \"Postprocessor/ExpandDims_1\"\n",
    "\n",
    "# # faster_rcnn_resnet101_coco\n",
    "# cut_node_1 = \"SecondStageBoxPredictor/AvgPool\"\n",
    "# cut_node_2 = \"SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Slice_14\"\n",
    "\n",
    "\n",
    "def _node_name(n):\n",
    "  if n.startswith(\"^\"):\n",
    "    return n[1:]\n",
    "  else:\n",
    "    return n.split(\":\")[0]\n",
    "\n",
    "\n",
    "input_graph = tf.Graph()\n",
    "with tf.Session(graph=input_graph):\n",
    "    score = tf.placeholder(tf.float32, shape=(None, 1917, 90), name=cut_node_1)\n",
    "    expand = tf.placeholder(tf.float32, shape=(None, 1917, 1, 4), name=cut_node_2)\n",
    "    for node in input_graph.as_graph_def().node:\n",
    "        if node.name == cut_node_1:\n",
    "            score_def = node\n",
    "        if node.name == cut_node_2:\n",
    "            expand_def = node\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    \n",
    "    dest_nodes = [cut_node_1,cut_node_2]\n",
    "\n",
    "    edges = {}\n",
    "    name_to_node_map = {}\n",
    "    node_seq = {}\n",
    "    seq = 0\n",
    "    for node in od_graph_def.node:\n",
    "      n = _node_name(node.name)\n",
    "#       print(n)\n",
    "      name_to_node_map[n] = node\n",
    "      edges[n] = [_node_name(x) for x in node.input]\n",
    "      node_seq[n] = seq\n",
    "      seq += 1\n",
    "    print(len(od_graph_def.node))\n",
    "\n",
    "    for d in dest_nodes:\n",
    "      assert d in name_to_node_map, \"%s is not in graph\" % d\n",
    "\n",
    "    nodes_to_keep = set()\n",
    "    next_to_visit = dest_nodes[:]\n",
    "    while next_to_visit:\n",
    "      n = next_to_visit[0]\n",
    "      del next_to_visit[0]\n",
    "      if n in nodes_to_keep:\n",
    "        continue\n",
    "      nodes_to_keep.add(n)\n",
    "      next_to_visit += edges[n]\n",
    "\n",
    "    nodes_to_keep_list = sorted(list(nodes_to_keep), key=lambda n: node_seq[n])\n",
    "\n",
    "    nodes_to_remove = set()\n",
    "    for n in node_seq:\n",
    "      if n in nodes_to_keep_list: continue\n",
    "      nodes_to_remove.add(n)\n",
    "    nodes_to_remove_list = sorted(list(nodes_to_remove), key=lambda n: node_seq[n])\n",
    "\n",
    "    keep = graph_pb2.GraphDef()\n",
    "    for n in nodes_to_keep_list:\n",
    "      keep.node.extend([copy.deepcopy(name_to_node_map[n])])\n",
    "\n",
    "    remove = graph_pb2.GraphDef()\n",
    "    remove.node.extend([score_def])\n",
    "    remove.node.extend([expand_def])\n",
    "    for n in nodes_to_remove_list:\n",
    "      remove.node.extend([copy.deepcopy(name_to_node_map[n])])\n",
    "\n",
    "    with tf.device('/gpu:1'):\n",
    "      tf.import_graph_def(keep, name='')\n",
    "    with tf.device('/cpu:0'):\n",
    "      tf.import_graph_def(remove, name='')\n",
    "    print(len(keep.node))\n",
    "    print(len(remove.node))\n",
    "    for node in keep.node:\n",
    "        print(node.name)\n",
    "# NUM_CLASSES = 90\n",
    "# label_map = label_map_util.load_labelmap('data/mscoco_label_map.pbtxt')\n",
    "# categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "# category_index = label_map_util.create_category_index(categories)\n",
    "PATH_TO_LABELS = os.path.join('/home/shuo/Shuo/tensorflow_models/research/object_detection/data', 'mscoco_label_map.pbtxt')\n",
    "NUM_CLASSES = 90\n",
    "if MODEL_NAME[-5:] == 'kitti':\n",
    "    PATH_TO_LABELS = os.path.join('/home/shuo/Shuo/tensorflow_models/research/object_detection/data', 'kitti_label_map.pbtxt')\n",
    "    NUM_CLASSES = 2\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "    \n",
    "    \n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = '/home/shuo/Shuo/tensorflow_models/research/object_detection/test_images'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import timeline\n",
    "\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph,config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    score_out = detection_graph.get_tensor_by_name('Postprocessor/convert_scores:0')\n",
    "    expand_out = detection_graph.get_tensor_by_name('Postprocessor/ExpandDims_1:0')\n",
    "    score_in = detection_graph.get_tensor_by_name('Postprocessor/convert_scores_1:0')\n",
    "    expand_in = detection_graph.get_tensor_by_name('Postprocessor/ExpandDims_1_1:0')\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    i = 0\n",
    "#     for image_path in TEST_IMAGE_PATHS:\n",
    "    for _ in range(10):\n",
    "      image_path = TEST_IMAGE_PATHS[1]\n",
    "      i += 1\n",
    "      image = Image.open(image_path)\n",
    "      image_np = load_image_into_numpy_array(image)\n",
    "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#       options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "#       run_metadata = tf.RunMetadata()\n",
    "      start_time = time.time()\n",
    "      \n",
    "      (score, expand) = sess.run([score_out, expand_out], feed_dict={image_tensor: image_np_expanded})\n",
    "#       (boxes, scores, classes, num) = sess.run(\\\n",
    "#             [detection_boxes, detection_scores, detection_classes, num_detections], \\\n",
    "#             feed_dict={score_in:score, expand_in: expand}, \\\n",
    "#             options=options, run_metadata=run_metadata)\n",
    "      (boxes, scores, classes, num) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={score_in:score, expand_in: expand})\n",
    "      print('Iteration %d: %.3f sec'%(i, time.time()-start_time))\n",
    "\n",
    "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "       np.squeeze(boxes),\n",
    "      np.squeeze(classes).astype(np.int32),\n",
    "      np.squeeze(scores),\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)\n",
    "    \n",
    "    \n",
    "# #     Create the Timeline object, and write it to a json file\n",
    "#     fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n",
    "#     chrome_trace = fetched_timeline.generate_chrome_trace_format()\n",
    "#     with open('Experiment3.json' , 'w') as f:\n",
    "#       f.write(chrome_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
